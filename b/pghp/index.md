---
layout: fa
title:  "کتاب: PostgreSQL High Performance"
translations: "fa"
---


## معرفی

### معرفی کتاب

* **نام:** PostgreSQL High Performance
* **نویسنده:** Gregory Smith، مشاور، 2ndQuadrant
* **ناشر:** Packet، اکتبر ۲۰۱۰
* **شابک:** 978-1-849510-30-1

### معرفی کلی

بهترین کتاب و کامل‌ترین منبع برای بهینه‌سازی کارایی سرور PostgreSQL، و تا حدی هم راهنمایی برای بهینه‌سازی پرسمان‌ها.

از پیش‌گفتار کتاب:

> PostgreSQL has become an increasingly viable database platform to serve as storage
for applications, from classic corporate database use to the latest web apps. But
getting the best performance from it has not been an easy subject to learn. You need
just the right combination of rules of thumb to get started, solid monitoring, and
maintenance to keep your system running well, suggestions for troubleshooting, and
hints for add-on tools to add the features the core database doesn't try to handle on
its own.

## فصل‌ها

### فصل یک: نسخه‌های PG

ممکن است PG کمی کند باشد، ولی به این خاطر که غالبا انجام «کار درست» زمان‌برتر است. اگر درستی داده برایمان مهم هست، که در کاربردهای واقعی هست، این روش تنها راه قابل قبول است. 

نسخه ۸.۱ سال ۲۰۰۵، نسخه ۸.۳ سال ۲۰۰۸

استفاده از pg_upgrade که از نسخه‌ی ۹.۰ به بعد در هسته PG قرار گرفته است، برای به روزرسانی بدون نیاز به dump و restore (که باعث قطعی سرویس است)، بسیار کارا است.

برای برخی از پرسمان‌های پیچیده‌تر [TPC-H][tpch] کارکرد PG مطلوب نیست، ولی الزاما این به معنی ناکارآمدی PG در کارکردهای واقعی نیست. پایگاه داده‌هایی مانند [GreenPlum][greenplum] برای کارکردهای انباره داده‌ای می‌توانند مفیدتر باشند.

[tpch]: http://www.tpc.org/tpch/
[greenplum]: http://greenplum.org/

به جز هسته‌ی پایگاه داده، ابزارهای زیادی برای PG در دسترس هستند که معمولا بسیار به کار می‌آیند. بعضی از ابزارها، با نام postgresql-common ابزارهایی هستند که با وجود توسعه توسط خود تیم اصلی توسعه‌ی هسته، ولی به آن میزان مورد تست قرار نمی‌گیرند. 

**فرآیند مقیاس‌دهی یک سیستم:** انتخاب سخت‌افزار، راه‌اندازی دیسک، تنظیمات سرور، رصد کارایی و اجرای خوب پرسمان‌ها، بهبود برسمان‌ها و نمایه‌ها، کش و مدیریت اتصال‌ها، تقسیم خواندن در چند سرور، تقسیم جدول‌های بزرگ در چند سرور با نوشتن همزمان

بهترین و حتی تنها راه برای شناسایی گلوگاه و مشکل فعلی پایگاه داده، ارزیابی کارایی سیستم است. تقریبا هیچ‌گاه نمی‌توان تا رفع گلوگاه فعلی سیستم، در مورد گلوگاه‌ها بهبودهای آتی آن پیش‌بینی داشت. در نتیجه، بهترین راه، رصد دقیق و ایجاد تغییرات تدریجی و جزئی است. همچنین سیستم با بهینه‌سازی ممکن است بسیار تغییر کند و همین باعث تغییر شرایط آتی و راه حل‌های پیش رو می‌شود. همیشه ارزیابی بهتر است حدس است، و تغییرات هم نیازمند ارزیابی برای تایید هستند. داشتن روشی نظام‌مند برای ارزیابی سطوح مختلف سیستم از سخت‌افزار به بالا، و از ابتدای کار سرور، جهت اطمینان کامل بسیار مهم است.


### فصل دو: سخت‌افزار

#### پردازنده

دو تصمیم اصلی: رده‌ی پردازنده، و تعداد بیشتر هسته یا هسته‌های قوی‌تر. برای پرسمان‌های پیچیده‌تر، هسته‌های قوی‌تر بهتر هستند و برای پاسخگویی به کاربران بیشتر (پرسمان‌های همزمان بیشتر)، تعداد هسته‌های بیشتر. دیدن تعداد پردازه‌های فعال در یک سرور در حال کار، مثلا با استفاده از top، برای این تصمیم مفید است. PG هر پرسمان را تنها روی یک هسته اجرا می‌کند، برخی سیستم‌های دیگر البته ویژگی‌ای با نام پرسمان موازی (Parallel Query) دارند که به معنی اجرای یک پرسمان روی چند هسته است. در نتیجه راه اجرا شدن سریع‌تر پرسمان‌ها، داشتن هسته‌های قوی‌تر است. عملیات dump و COPY هم محدود به یک هسته بوده و معمولا گلوگاه اصلی برایشان پردازنده است.

#### حافظه

معمولا داشتن حافظه‌ی RAM بیشتر، کمک زیادی به کارایی می‌کند، به ویژه در زمانی که working data set در حدی است که در حافظه می‌گنجد. در صورتی که حجم کلی داده به هر حال کوچک است، یا بزرگ‌تر از حدی است که در حافظه جا شود (و در عین حال SCAN جدوال مورد نیاز پرسمان‌ها است)، افزودن حافظه اولویت ندارد. بررسی buffer cache اطلاعات خوبی در مورد میزان حافظه‌ی مورد مصرف و بخش‌هایی از حافظه که PG ترجیح می‌دهد در حافظه نگهداری کند، در اختیار قرار می‌دهد.

برای نمایه‌ها که به صورت BTree ذخیره می‌شوند، در اختیار بودن میزان بیشتری حافظه باعث می‌شود که یافتن در نمایه بسیار سریع‌تر باشد. حتی اگر تمام درخت مربوط به اندیس در حافظه نباشد، بودن بلوک‌های پرکاربردتر بالاتر درخت در حافظه (کش دیسک) کمک زیادی به سرعت بررسی نمایه می‌کند.

#### دیسک

احتمال گلوگاه بودن دیسک، مخصوصا در زمانی که تعداد دیسک‌ها کم است، زیاد است.

استفاده از RAID 10 بهترین کارایی را برای پایگاه داده‌ها فراهم می‌کند، به ویژه زمانی که نوشتن روی دیسک زیاد باشد. RAID5 از نظر میزان استفاده از فضا بهینه‌تر است ولی به خصوص کارایی نوشتن آن پایین‌تر است. همچنین RAID6 که امکان تحمل خطای دو دیسک را فراهم می‌کند، می‌تواند مفید باشد. چرا که معمولا بازیابی دیسک‌ها در زمان خراب شدن یک دیسک، زمان‌بر است؛ و دیسک‌هایی که با هم ساخته شده‌اند، با احتمال زیادی همزمان خراب می‌شوند. تعداد دیسک‌های مورد نیاز برای رسیدن به حدی از ظرفیت ذخیره‌سازی نیز با توجه به تعداد گنجایش سرور و فضای رک مورد نیاز، می‌تواند مهم باشد.

استفاده از دیسک‌هایی که مخصوص سرور یا RAID هستند، می‌تواند کمک کند. امکاناتی مانند SMART برای گزارش سلامتی دیسک و به ویژه [TLER][tler] برای هماهنگی بهتر فرآیند اصلاح خطای درونی دیسک (ECR) و کارکرد کنترلر RAID، بسیار در کارایی موثر هستند. دیسک‌های خارجی، که با پروتکل‌هایی غیر از eSATA متصل باشند، معمولا از این چنین امکاناتی پشتیبانی نمی‌کنند.

[tler]: https://en.wikipedia.org/wiki/Error_recovery_control

در مورد انتخاب دیسک، می‌توان از گزارش‌های در این رابطه، مثلا [گزارش گوگل ۲۰۱۱][google-disk]، می‌توان استفاده کرد. راه مناسب‌تری نیز استفاده از دیسک‌های موجود در بازار برای مدت به نسبت طولانی‌تر است، که نتایج مطلوبی برایشان گزارش شده باشد. در حالت کلی نیز استفاده از دیسک‌ها و سخت‌افزار مخصوص سرور، می‌تواند از بسیاری از مشکلات جزئی احتمالی، مانند عمر کم یا ناپایداری تکنولوژی یا تفاوت نسخه Firmware، جلوگیری کند.

[google-disk]: http://research.google.com/archive/disk_failures.pdf

در استفاده از دیسک‌های SSD به خاطر داشتن write-cache حتما باید از طراحی خوب آن و داشتن باتری اطمینان حاصل کرد؛ چرا که حتی در صورت استفاده از کارت کنترلر دارای باتری، به دلیل اساسی بودن write-cache در طول عمر SSDها، حتی در صورت فرمان کارت کنترلر، این دیسک‌ها کش خود را غیرفعال نمی‌کنند.

استفاده از کنترلر دیسک خوب و در نتیجه RAID سخت‌افزاری و مهم‌تر از آن کش نوشتن مناسب، یکی از اساسی‌ترین فاکتورها در بالا بردن کارایی PG است، که به دلیل محدودیت‌های ذاتی سخت‌افزاری، به سختی با راهکارهای نرم‌افزاری (مثلا RAID نرم‌افزاری یا DMA) قابل پوشش است. مدل P800 و همچنین P600 و P400، مدل‌های مناسبی از این کنترلرها برای سرورهای HP هستند.

استفاده از SAN به دلیل قیمت بالاتر، پیچیدگی راه‌اندازی مطلوب، و احتمال گلوگاه شدن اتصال شبکه، تنها در شرایطی که حجم مورد نیاز ذخیره‌سازی بسیار زیاد است و یک سرور توانایی آن را ندارد، مثلا بیش از ۲۴ دیسک، قابل توجیه است. دیسک‌های معمول (اتصال مستقیم یا DAS) غالبا بهترین کارایی را با قیمتی منطقی فراهم می‌کنند.

#### کش دیسک و اطمینان از داده‌ها

اگر داده‌ها مستقیما برای نوشتن به دیسک منتقل شوند، به آن فرآیند write-through cache و اگر در حافظه‌ی واسطی ذخیره شوند و با تاخیر برای نوشتن ارسال شوند، write-back cache گفته می‌شود. در حالت دوم که ناهمگام است، ممکن است حتی چند دقیقه از زمان تایید دریافت دستور نوشتن تا اتمام واقعی نوشته شده روی دیسک، فاصله وجود داشته باشد.

برای تضمین پایداری قبل از انجام هر تراکنش، شرح آن در WAL نوشته می‌شود. برای اطمینان از پایداری تراکنش، از قبل COMMIT هر تراکنش، صفحات مربوط به WAL آن روی دیسک flush می‌شوند.

تنظیم `synchronous_commit` در زمان شروع هر تراکنش، مشخص می‌شود که تراکنش همگام یا ناهمگام باشد (تنظیم سطح تراکنش نه سرور). در تراکنش‌های ناهمگام ولی این عمل انجام نمی‌شود که زمانی که از دست دادن داده در صورت خرابی سرور قابل تحمل باشد، مثلا برای اطلاعات لاگ، باعث بالا رفتن کارایی می‌شود. پردازه‌ی `WAL Writer` در بازه‌های زمانی مشخص (به اندازه‌ی `wal_writer_delay`، پیش‌فرض ۲۰۰ میلی‌ثانیه) محتویات WAL را flush می‌کند.

در صورت flush نشدن WAL، مشکل متحمل از دست دادن داده است، نه خرابی داده‌ها. چرا که در صورت خرابی سرور، پس از بازآوری، با اجرای کامل WAL، داده به وضعیتی self-consistent می‌رسد. حدس من هم هست که تراکنش‌های همگام و ناهمگام همزمان به این صورت مدیریت می‌شود که WAL همیشه از ابتدا تا یک مکان به صورت کامل flush می‌شود، و در نتیجه اگر یک تراکنش روی دیسک flush شده باشد، حتما تمامی تراکنش‌های قبلی آن هم flush شده‌اند و در نتیجه‌ی اجرای WAL باعث رسیدن به یک نقطه‌ی واقعی و درست می‌شود.

در صورت غیرفعال بودن پارامتر `fsync` در تنظیمات، تمامی اقدامات مربوط به اطمینان از انتقال WAL روی دیسک، غیرفعال می‌شود. از جمله در کل `fsync` و توابع مشابه آن فراخوانی نمی‌شود.

**سطوح مختلف کش**

* کش سیستم عامل: ممکن است چندین GB باشد، و مثلا با `int fsync(int fd)‍` می‌توان آن را روی دیسک منتقل کرد. روش انتقال با پارامتر `wal_sync_method` تنظیمات مشخص می‌شود. در فایل سیستم‌های جدید، فراخوانی این تابع باعث نوشتن مستقیم روی دیسک یا منتظر ماندن برای خالی شدن کش مربوطه‌ی دیسک نیز می‌شود.
* کش کنترلر دیسک: معمولا کنترلرهای RAID و SAN خود دارای کشی بین 128MB تا چند GB (در SANها) هستند. معمولا تا زمانی که داده‌ها در این کش جا شوند، بلافاصله به سیستم عامل موفقیت نوشتن گزارش می‌شود و داده‌ها به تدریج روی دیسک ذخیره می‌شوند. می‌تواند دارای باتری برای حفظ داده‌ها باشد.
* کش درایو (خود دیسک): بین 8MB تا 32MB، در صورت فعال بودن حتما write-back، و همیشه ناپایدار (بدون باتری).

پیشنهاد، فعال نگهداشتن fsync، اطمینان از پیاده‌سازی درست fsync در فایل سیستم مورد استفاده، اطمینان از درست بودن باتری کنترلر دیسک، و غیرفعال کردن کش درایوها است. همچنین در شرایط خاص مانند قطعی برق، بهترین راه عدم اطمینان به روش‌های تست و تجربه نشده است. همچنین به دلیل احتمال بسیار بیشتر بروز مشکلات در این شرایط، مثلا متوجه شدن این موضوع که باتری UPS یا کنترلر دیسک خراب است، بهترین کار در شرایطی مانند قطعی برق، خاموش کردن معمول پایگاه داده و منتظر ماندن برای عادی شدن شرایط است.

کنترلرهای دیسک معمولا خود اقدام به غیرفعال‌کردن کش درایوها می‌کنند، ولی این کار با دستورات زیر نیز ممکن است:

    hdparm -I /dev/sda | grep "Write cache"
    hdparm -W 0 /dev/sda

با این حال غیرفعال کردن کش درایو، باعث پایین آمدن کارایی تا حد بسیار زیادی می‌شود، چرا که حداکثر در هر بار چرخش یک کلاینت یک کامیت می‌تواند انجام دهد، که متناظر حدود ۱۲۰ تراکنش در ثانیه می‌شود. در صورت عدم تمایل به از دست دادن اطمینان از درستی صد در صدی داده‌ها، یک راه فعال کردن `synchronous_commit` برای تراکنش‌های غیرمهم است.


### فصل سه: ارزیابی کارایی سخت‌افزار پایگاه داده

روش‌هایی برای ارزیابی کارایی اجزای مختلف سیستم از منظرهای مختلف برای اطمینان از کارایی خوب اولیه‌ی سخت‌افزار و همچنین سنجش مفید بودن تغییرات ایجاد شده در تنظیمات.


### فصل چهار: راه‌اندازی دیسک

#### فایل سیستم

به دلیل استفاده از متغیرهای ۳۲ بیتی، برخی از فایل سیستم‌ها محدودیت حداکثر 16TB برا اندازه‌ی کل دارند، که مقدار پایینی است. خود Partition Table درایو اگر به فرمت MBR باشد که در سیستم‌های BIOS مورد استفاده است، حداکثر اندازه‌ی پارتیشن (قابل بوت) می‌تواند 2TB باشد. فرمت `GPT: GUID Partition Table GPT` که پیش‌فرض در سیستم‌های UEFI است ولی در سیستم‌های BIOS هم به شرط پشتیبانی boot loader و سیستم عامل قابل استفاده است، برای داشتن پارتیشن‌های بزرگ‌تر باید استفاده شود. البته پارتیشن‌های بزرگ‌تر از 2TB اصلا برای بوت توصیه نمی‌شود چرا که پشتیبانی آن در سخت‌افزارها و ابزارها نو است.

برای اطمینان از ترتیب برخی اعمال نسبت به هم، کرنل لینوکس ویژگی `write barrier` را ارائه می‌کند. تمامی اعمال قبل از یک حائل، حتما از تک‌تک اعمال بعد از آن انجام می‌شوند. پیاده‌سازی حائل‌ها با استفاده از ارسال دستور خالی کردن کش به درایو صورت می‌گیرد، دستوراتی مانند `SYNCHRONIZE CACHE` یا `Force Unit Access` برای این منظور در درایوهای جدید پشتیبانی می‌شود. در فایل سیستم‌های `ext4` و `XFS` این امکان با ریزدانگی فایل، به درستی پیاده‌سازی شده است.

یکی از مهم‌ترین بهبودها، بالا بردن read_ahead است، که برای نوع کاری پایگاه داده بسیار مفید است. مقدار پیش‌فرض `128kb` است که افزایش آن در بازه‌ی `2mb` تا `8mb` و حتی بالاتر، تا زمانی که عملکرد خواندن در benchmarkها کاهش یابد، توصیه می‌شود و اثر بسیار زیادی در کارایی کل سیستم دارد. این پارامتر در `/sys/block/sda/queue/read_ahead_kb` قابل مشاهده و تنظیم است.

غیرفعال کردن نگهداری زمان آخرین دسترسی به فایل‌ها، با تنظیم `defaults,noatime` در `fstab` می‌تواند از تعداد زیادی نوشتن روی دیسک برای این منظور، جلوگیری کند. تنها برخی برنامه‌های پشتیبان‌گیری، ابزارهای قدیمی میل (مانند mutt و pine و sendmail) و برنامه‌هایی مانند tmpwatch از این ویژگی استفاده می‌کنند. پارامتر پیش‌فرض که relatime است، زمان دسترسی را تنها برای فایل‌های تغییر کرده می‌نویسد.

با توجه به استفاده‌ی کامل PG از حافظه‌ی در دسترسش، در یک سرور پایگاه داده، اولا `vm.overcommit_memory=2` تنظیم شود تا بیش از میزان در دسترس، اجازه‌ی اختصاص حافظه به پردازه‌ها داده نشود. همچنین، با وجود این که `swappiness` در صورت وجود برنامه‌های کمتر فعال، مفید است، ولی در صورت نیاز واقعی به حافظه، علاوه بر پایین آوردن کارایی، عملکرد سیستم را غیرقابل پیش‌بینی می‌کند. بنابراین همچنین پیشنهاد می‌شود که `vm.swappiness=0`.

کرنل با استفاده از سرویسی به نام pdflush صفحات تغییر یافته (کثیف) را مدتی در حافظه ذخیره کرده تا بتواند بهینه‌سازی‌هایی مانند تجمیع نوشتن‌های روی یک صفحه و تغییر ترتیب نوشتن‌ها را بتواند انجام دهد. دو پارامتر `vm.dirty_background_ration` و `vm.dirty_ratio` آستانه‌ی نوشتن را مشخص می‌کنند. در صورت زیاد بودن `vm.dirty_background_ration` به نسبت حافظه، در زمان نوشتن سیستم دچار وقفه‌ی IO قابل توجهی خواهد شد. میزان حافظه‌ی کثیف با `cat /proc/meminfo | grep Dirty` قابل مشاهده است. مقدار `vm.dirty_ratio` که آستانه‌ای است که پس از آن تمام پردازه‌ها باید به صورت مستقیم روی دیسک بنویسند، معمولا دو برابر آستانه‌ی نوشتن تعیین می‌شود. مشکل `write hogging` زمانی رخ می‌دهد که صفحات کثیف از آستانه‌ی نوشتن گذشته‌اند ولی هنوز روی دیسک منتقل نشدند، و به خاطر فعالیت نوشتن زیاد یک پردازه که باعث عبور از آستانه‌ی دوم نیز شده است، تمامی دیگر پردازه‌ها مجبور به نوشتن مستقیم روی دیسک می‌شوند.

تغییر IO Scheduler معمولا تاثیر زیادی در کارایی PG ندارد. تنها زمانی که کنترلر یا SAN خود کش بزرگی داشته باشد و در نتیجه اطلاعات کرنل از صفحات منتظر نوشتن کامل نباشد، استفاده از حالت `noop` مفید است. در باقی موارد، معمولا همان حالت پیش‌فرض `cfq` بهتر است. حالت `as` تنها برای حالاتی است که دیسک‌ها ضعیف باشند و نه برای سرورها.

اندازه‌ی رکوردها در ZFS به طور پیش‌فرض 128KB است که بسیار بزرگ از صفحات مورد استفاده‌ی PG با اندازه‌ی 8KB است. کارایی معمولی پایگاه داده در این حالت پایین است و برای حل باید اندازه رکورد در ZFS به 8KB کاهش یابد. همچنین خاموش کردن کش نوشتن نرم‌افزاری خود ZFS نیز پیشنهاد می‌شود. ZFS به دلیل ارائه‌ی دو ویژگی checksum برای نوشتن‌ها و همچنین امکان گرفتن snapshot، برای پایگاه داده‌ها می‌تواند مفید باشد.

#### ساختار پوشه‌های PG

پوشه base حاوی TABLESPACE پیش‌فرض (`pg_deault`)، پوشه‌ی global حاوی جداول سیستمی و کاتالوگ (`pg_global`)، پوشه‌ی `pg_clog` حاوی کامیت لاگ که به خصوص توسط VACUUM به شدت خوانده می‌شود، `pg_stat_tmp` که برای آمار استفاده می‌شود و نباید بزرگ شود، `pg_tblspc` که لینک‌های به TABLESPACEها را ذخیره می‌کند، `pg_xlog` که حاوی WAL است، `pg_subtrans` که برای زیرپرسمان‌ها است، `pg_multixact` که برای مواردی مانند قفل‌های سطرها به کار می‌رود، `pg_twophase` که برای 2PC است.

معمولا در اولین قدم، `pg_xlog` به یک دیسک دیگر منتقل می‌شود. سپس جدول‌های پرکاربرد در چند TABLESPACE روی دیسک‌های مختلف قرار می‌گیرند. پس از آن فایل‌های موقت می‌توانند روی یک دیسک دیگر منتقل شوند.

فایل‌های موقت دیسک علاوه بر جدول‌های موقت و نمایه‌های مربوط به آن‌ها، برای مرتب‌سازی نتایج پرسمان‌ها وقتی که مقدار `work_mem` برای این منظور کافی نباشد، استفاده می‌شود. با پارامتر `temp_tablespaces` می‌توان برای هر پایگاه داده یک یا چند TABLESPACE مشخص کرد تا از آن‌ها (به ترتیب) برای فایل‌های موقت دیسک استفاده کرد. به صورت پیش‌فرض هم در `base/pgsql_tmp` ذخیره می‌شوند. همچنین نیاز به اطمینان برای فایل‌های موقت نیست، در نتیجه می‌توان آن‌ها را روی دیسک‌های مربوط به سیستم عامل هم قرار داد، اگر دیسک‌های مربوطه بار کمی دارند.

با توجه به پارامترهای مختلف ممکن برای چینش درایوها، تنها راه مطمئن ارزیابی گام به گام تغییرات و استفاده از جداسازی درایوهای بخش‌های مختلف سیستم است. با توجه به تفاوت سیستم‌های تست و نهایی، بهترین زمان ارزیابی، زمان اضافه کردن سرورهای جدید نهایی است. یکی نبودن WAL و سیستم عامل به دلیل تفاوت روند کاری، پیشنهاد می‌شود. جداسازی WAL نیاز به تخمینی از نسبت کار پایگاه داده به WAL دارد، یک تخمین معمول، سه به یک است و پیشنهاد می‌شوند تعداد دیسک‌های پایگاه داده حداقل سه برابر دیسک‌های WAL باشد. جداسازی دیسک‌های مربوط به اجزای مختلف، حداقل دارای این مزیت است که دید بهتری نسبت به کارکرد هر جز می‌دهد. ولی به هر حال جداسازی کارکردی یا محول کردن مدیریت IO به سیستم عامل، کاملا وابسته به نوع کار است باید با ارزیابی در مورد آن به نتیجه رسید.






#### منابع مفید

* [راهنمای استفاده از hdparm][hdparm]
* [راهنمای پارامترهای کرنل sysfs][kernel-sysfs]
* [بهبود کارایی دیسک][tuning-disk-io]

[hdparm]: http://www.linux-magazine.com/Online/Features/Tune-Your-Hard-Disk-with-hdparm
[kernel-sysfs]: https://www.kernel.org/doc/Documentation/block/queue-sysfs.txt
[tuning-disk-io]: http://cromwell-intl.com/linux/performance-tuning/disks.html
