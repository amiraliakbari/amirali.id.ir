---
layout: fa
title:  "کتاب: PostgreSQL High Performance"
translations: "fa"
---


## معرفی

### معرفی کتاب

* **نام:** PostgreSQL High Performance
* **نویسنده:** Gregory Smith، مشاور، 2ndQuadrant
* **ناشر:** Packet، اکتبر ۲۰۱۰
* **شابک:** 978-1-849510-30-1

### معرفی کلی

بهترین کتاب و کامل‌ترین منبع برای بهینه‌سازی کارایی سرور PostgreSQL، و تا حدی هم راهنمایی برای بهینه‌سازی پرسمان‌ها.

از پیش‌گفتار کتاب:

> PostgreSQL has become an increasingly viable database platform to serve as storage
for applications, from classic corporate database use to the latest web apps. But
getting the best performance from it has not been an easy subject to learn. You need
just the right combination of rules of thumb to get started, solid monitoring, and
maintenance to keep your system running well, suggestions for troubleshooting, and
hints for add-on tools to add the features the core database doesn't try to handle on
its own.

## فصل‌ها

### فصل یک: نسخه‌های PG

ممکن است PG کمی کند باشد، ولی به این خاطر که غالبا انجام «کار درست» زمان‌برتر است. اگر درستی داده برایمان مهم هست، که در کاربردهای واقعی هست، این روش تنها راه قابل قبول است. 

نسخه ۸.۱ سال ۲۰۰۵، نسخه ۸.۳ سال ۲۰۰۸

استفاده از pg_upgrade که از نسخه‌ی ۹.۰ به بعد در هسته PG قرار گرفته است، برای به روزرسانی بدون نیاز به dump و restore (که باعث قطعی سرویس است)، بسیار کارا است.

برای برخی از پرسمان‌های پیچیده‌تر [TPC-H][tpch] کارکرد PG مطلوب نیست، ولی الزاما این به معنی ناکارآمدی PG در کارکردهای واقعی نیست. پایگاه داده‌هایی مانند [GreenPlum][greenplum] برای کارکردهای انباره داده‌ای می‌توانند مفیدتر باشند.

[tpch]: http://www.tpc.org/tpch/
[greenplum]: http://greenplum.org/

به جز هسته‌ی پایگاه داده، ابزارهای زیادی برای PG در دسترس هستند که معمولا بسیار به کار می‌آیند. بعضی از ابزارها، با نام postgresql-common ابزارهایی هستند که با وجود توسعه توسط خود تیم اصلی توسعه‌ی هسته، ولی به آن میزان مورد تست قرار نمی‌گیرند. 

**فرآیند مقیاس‌دهی یک سیستم:** انتخاب سخت‌افزار، راه‌اندازی دیسک، تنظیمات سرور، رصد کارایی و اجرای خوب پرسمان‌ها، بهبود برسمان‌ها و نمایه‌ها، کش و مدیریت اتصال‌ها، تقسیم خواندن در چند سرور، تقسیم جدول‌های بزرگ در چند سرور با نوشتن همزمان

بهترین و حتی تنها راه برای شناسایی گلوگاه و مشکل فعلی پایگاه داده، ارزیابی کارایی سیستم است. تقریبا هیچ‌گاه نمی‌توان تا رفع گلوگاه فعلی سیستم، در مورد گلوگاه‌ها بهبودهای آتی آن پیش‌بینی داشت. در نتیجه، بهترین راه، رصد دقیق و ایجاد تغییرات تدریجی و جزئی است. همچنین سیستم با بهینه‌سازی ممکن است بسیار تغییر کند و همین باعث تغییر شرایط آتی و راه حل‌های پیش رو می‌شود. همیشه ارزیابی بهتر است حدس است، و تغییرات هم نیازمند ارزیابی برای تایید هستند. داشتن روشی نظام‌مند برای ارزیابی سطوح مختلف سیستم از سخت‌افزار به بالا، و از ابتدای کار سرور، جهت اطمینان کامل بسیار مهم است.


### فصل دو: سخت‌افزار

#### پردازنده

دو تصمیم اصلی: رده‌ی پردازنده، و تعداد بیشتر هسته یا هسته‌های قوی‌تر. برای پرسمان‌های پیچیده‌تر، هسته‌های قوی‌تر بهتر هستند و برای پاسخگویی به کاربران بیشتر (پرسمان‌های همزمان بیشتر)، تعداد هسته‌های بیشتر. دیدن تعداد پردازه‌های فعال در یک سرور در حال کار، مثلا با استفاده از top، برای این تصمیم مفید است. PG هر پرسمان را تنها روی یک هسته اجرا می‌کند، برخی سیستم‌های دیگر البته ویژگی‌ای با نام پرسمان موازی (Parallel Query) دارند که به معنی اجرای یک پرسمان روی چند هسته است. در نتیجه راه اجرا شدن سریع‌تر پرسمان‌ها، داشتن هسته‌های قوی‌تر است. عملیات dump و COPY هم محدود به یک هسته بوده و معمولا گلوگاه اصلی برایشان پردازنده است.

#### حافظه

معمولا داشتن حافظه‌ی RAM بیشتر، کمک زیادی به کارایی می‌کند، به ویژه در زمانی که working data set در حدی است که در حافظه می‌گنجد. در صورتی که حجم کلی داده به هر حال کوچک است، یا بزرگ‌تر از حدی است که در حافظه جا شود (و در عین حال SCAN جدوال مورد نیاز پرسمان‌ها است)، افزودن حافظه اولویت ندارد. بررسی buffer cache اطلاعات خوبی در مورد میزان حافظه‌ی مورد مصرف و بخش‌هایی از حافظه که PG ترجیح می‌دهد در حافظه نگهداری کند، در اختیار قرار می‌دهد.

برای نمایه‌ها که به صورت BTree ذخیره می‌شوند، در اختیار بودن میزان بیشتری حافظه باعث می‌شود که یافتن در نمایه بسیار سریع‌تر باشد. حتی اگر تمام درخت مربوط به اندیس در حافظه نباشد، بودن بلوک‌های پرکاربردتر بالاتر درخت در حافظه (کش دیسک) کمک زیادی به سرعت بررسی نمایه می‌کند.

#### دیسک

احتمال گلوگاه بودن دیسک، مخصوصا در زمانی که تعداد دیسک‌ها کم است، زیاد است.

استفاده از RAID 10 بهترین کارایی را برای پایگاه داده‌ها فراهم می‌کند، به ویژه زمانی که نوشتن روی دیسک زیاد باشد. RAID5 از نظر میزان استفاده از فضا بهینه‌تر است ولی به خصوص کارایی نوشتن آن پایین‌تر است. همچنین RAID6 که امکان تحمل خطای دو دیسک را فراهم می‌کند، می‌تواند مفید باشد. چرا که معمولا بازیابی دیسک‌ها در زمان خراب شدن یک دیسک، زمان‌بر است؛ و دیسک‌هایی که با هم ساخته شده‌اند، با احتمال زیادی همزمان خراب می‌شوند. تعداد دیسک‌های مورد نیاز برای رسیدن به حدی از ظرفیت ذخیره‌سازی نیز با توجه به تعداد گنجایش سرور و فضای رک مورد نیاز، می‌تواند مهم باشد.

استفاده از دیسک‌هایی که مخصوص سرور یا RAID هستند، می‌تواند کمک کند. امکاناتی مانند SMART برای گزارش سلامتی دیسک و به ویژه [TLER][tler] برای هماهنگی بهتر فرآیند اصلاح خطای درونی دیسک (ECR) و کارکرد کنترلر RAID، بسیار در کارایی موثر هستند. دیسک‌های خارجی، که با پروتکل‌هایی غیر از eSATA متصل باشند، معمولا از این چنین امکاناتی پشتیبانی نمی‌کنند.

[tler]: https://en.wikipedia.org/wiki/Error_recovery_control

در مورد انتخاب دیسک، می‌توان از گزارش‌های در این رابطه، مثلا [گزارش گوگل ۲۰۱۱][google-disk]، می‌توان استفاده کرد. راه مناسب‌تری نیز استفاده از دیسک‌های موجود در بازار برای مدت به نسبت طولانی‌تر است، که نتایج مطلوبی برایشان گزارش شده باشد. در حالت کلی نیز استفاده از دیسک‌ها و سخت‌افزار مخصوص سرور، می‌تواند از بسیاری از مشکلات جزئی احتمالی، مانند عمر کم یا ناپایداری تکنولوژی یا تفاوت نسخه Firmware، جلوگیری کند.

[google-disk]: http://research.google.com/archive/disk_failures.pdf

در استفاده از دیسک‌های SSD به خاطر داشتن write-cache حتما باید از طراحی خوب آن و داشتن باتری اطمینان حاصل کرد؛ چرا که حتی در صورت استفاده از کارت کنترلر دارای باتری، به دلیل اساسی بودن write-cache در طول عمر SSDها، حتی در صورت فرمان کارت کنترلر، این دیسک‌ها کش خود را غیرفعال نمی‌کنند.

استفاده از کنترلر دیسک خوب و در نتیجه RAID سخت‌افزاری و مهم‌تر از آن کش نوشتن مناسب، یکی از اساسی‌ترین فاکتورها در بالا بردن کارایی PG است، که به دلیل محدودیت‌های ذاتی سخت‌افزاری، به سختی با راهکارهای نرم‌افزاری (مثلا RAID نرم‌افزاری یا DMA) قابل پوشش است. مدل P800 و همچنین P600 و P400، مدل‌های مناسبی از این کنترلرها برای سرورهای HP هستند.

استفاده از SAN به دلیل قیمت بالاتر، پیچیدگی راه‌اندازی مطلوب، و احتمال گلوگاه شدن اتصال شبکه، تنها در شرایطی که حجم مورد نیاز ذخیره‌سازی بسیار زیاد است و یک سرور توانایی آن را ندارد، مثلا بیش از ۲۴ دیسک، قابل توجیه است. دیسک‌های معمول (اتصال مستقیم یا DAS) غالبا بهترین کارایی را با قیمتی منطقی فراهم می‌کنند.

#### کش دیسک و اطمینان از داده‌ها

اگر داده‌ها مستقیما برای نوشتن به دیسک منتقل شوند، به آن فرآیند write-through cache و اگر در حافظه‌ی واسطی ذخیره شوند و با تاخیر برای نوشتن ارسال شوند، write-back cache گفته می‌شود. در حالت دوم که ناهمگام است، ممکن است حتی چند دقیقه از زمان تایید دریافت دستور نوشتن تا اتمام واقعی نوشته شده روی دیسک، فاصله وجود داشته باشد.

برای تضمین پایداری قبل از انجام هر تراکنش، شرح آن در WAL نوشته می‌شود. برای اطمینان از پایداری تراکنش، از قبل COMMIT هر تراکنش، صفحات مربوط به WAL آن روی دیسک flush می‌شوند.

تنظیم `synchronous_commit` در زمان شروع هر تراکنش، مشخص می‌شود که تراکنش همگام یا ناهمگام باشد (تنظیم سطح تراکنش نه سرور). در تراکنش‌های ناهمگام ولی این عمل انجام نمی‌شود که زمانی که از دست دادن داده در صورت خرابی سرور قابل تحمل باشد، مثلا برای اطلاعات لاگ، باعث بالا رفتن کارایی می‌شود. پردازه‌ی `WAL Writer` در بازه‌های زمانی مشخص (به اندازه‌ی `wal_writer_delay`، پیش‌فرض ۲۰۰ میلی‌ثانیه) محتویات WAL را flush می‌کند.

در صورت flush نشدن WAL، مشکل متحمل از دست دادن داده است، نه خرابی داده‌ها. چرا که در صورت خرابی سرور، پس از بازآوری، با اجرای کامل WAL، داده به وضعیتی self-consistent می‌رسد. حدس من هم هست که تراکنش‌های همگام و ناهمگام همزمان به این صورت مدیریت می‌شود که WAL همیشه از ابتدا تا یک مکان به صورت کامل flush می‌شود، و در نتیجه اگر یک تراکنش روی دیسک flush شده باشد، حتما تمامی تراکنش‌های قبلی آن هم flush شده‌اند و در نتیجه‌ی اجرای WAL باعث رسیدن به یک نقطه‌ی واقعی و درست می‌شود.

در صورت غیرفعال بودن پارامتر `fsync` در تنظیمات، تمامی اقدامات مربوط به اطمینان از انتقال WAL روی دیسک، غیرفعال می‌شود. از جمله در کل `fsync` و توابع مشابه آن فراخوانی نمی‌شود.

**سطوح مختلف کش**

* کش سیستم عامل: ممکن است چندین GB باشد، و مثلا با `int fsync(int fd)‍` می‌توان آن را روی دیسک منتقل کرد. روش انتقال با پارامتر `wal_sync_method` تنظیمات مشخص می‌شود. در فایل سیستم‌های جدید، فراخوانی این تابع باعث نوشتن مستقیم روی دیسک یا منتظر ماندن برای خالی شدن کش مربوطه‌ی دیسک نیز می‌شود.
* کش کنترلر دیسک: معمولا کنترلرهای RAID و SAN خود دارای کشی بین 128MB تا چند GB (در SANها) هستند. معمولا تا زمانی که داده‌ها در این کش جا شوند، بلافاصله به سیستم عامل موفقیت نوشتن گزارش می‌شود و داده‌ها به تدریج روی دیسک ذخیره می‌شوند. می‌تواند دارای باتری برای حفظ داده‌ها باشد.
* کش درایو (خود دیسک): بین 8MB تا 32MB، در صورت فعال بودن حتما write-back، و همیشه ناپایدار (بدون باتری).

پیشنهاد، فعال نگهداشتن fsync، اطمینان از پیاده‌سازی درست fsync در فایل سیستم مورد استفاده، اطمینان از درست بودن باتری کنترلر دیسک، و غیرفعال کردن کش درایوها است. همچنین در شرایط خاص مانند قطعی برق، بهترین راه عدم اطمینان به روش‌های تست و تجربه نشده است. همچنین به دلیل احتمال بسیار بیشتر بروز مشکلات در این شرایط، مثلا متوجه شدن این موضوع که باتری UPS یا کنترلر دیسک خراب است، بهترین کار در شرایطی مانند قطعی برق، خاموش کردن معمول پایگاه داده و منتظر ماندن برای عادی شدن شرایط است.

کنترلرهای دیسک معمولا خود اقدام به غیرفعال‌کردن کش درایوها می‌کنند، ولی این کار با دستورات زیر نیز ممکن است:

    hdparm -I /dev/sda | grep "Write cache"
    hdparm -W 0 /dev/sda

با این حال غیرفعال کردن کش درایو، باعث پایین آمدن کارایی تا حد بسیار زیادی می‌شود، چرا که حداکثر در هر بار چرخش یک کلاینت یک کامیت می‌تواند انجام دهد، که متناظر حدود ۱۲۰ تراکنش در ثانیه می‌شود. در صورت عدم تمایل به از دست دادن اطمینان از درستی صد در صدی داده‌ها، یک راه فعال کردن `synchronous_commit` برای تراکنش‌های غیرمهم است.


### فصل سه: ارزیابی کارایی سخت‌افزار پایگاه داده

روش‌هایی برای ارزیابی کارایی اجزای مختلف سیستم از منظرهای مختلف برای اطمینان از کارایی خوب اولیه‌ی سخت‌افزار و همچنین سنجش مفید بودن تغییرات ایجاد شده در تنظیمات.

